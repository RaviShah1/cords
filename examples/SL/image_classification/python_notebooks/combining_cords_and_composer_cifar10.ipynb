{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Combining Coords and Composer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaviShah1/cords/blob/main/examples/SL/image_classification/python_notebooks/combining_cords_and_composer_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install \n",
        "clones cords github\n",
        "\n",
        "pip installs cords prerequisite libraries and mosiacml"
      ],
      "metadata": {
        "id": "FY7NL3_0Z2W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/decile-team/cords.git\n",
        "%cd cords\n",
        "%ls"
      ],
      "metadata": {
        "id": "pJewp117QDUI",
        "outputId": "4e6a8d05-0649-42fd-9ffa-bcf714c709d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cords' already exists and is not an empty directory.\n",
            "/content/cords\n",
            "\u001b[0m\u001b[01;34mbenchmarks\u001b[0m/   \u001b[01;34mcords\u001b[0m/  \u001b[01;34mexamples\u001b[0m/    README.md      setup.py      train_sl.py\n",
            "CITATION.CFF  \u001b[01;34mdata\u001b[0m/   LICENSE.txt  \u001b[01;34mrequirements\u001b[0m/  \u001b[01;34mtests\u001b[0m/        train_ssl.py\n",
            "\u001b[01;34mconfigs\u001b[0m/      \u001b[01;34mdocs\u001b[0m/   model.pt     \u001b[01;34mresults\u001b[0m/       train_hpo.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dotmap apricot-select ray[default] ray[tune] mosaicml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37QszJkXYAZz",
        "outputId": "0dae86d8-48e8-45de-cf7f-a0c937536720"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dotmap in /usr/local/lib/python3.7/dist-packages (1.3.30)\n",
            "Requirement already satisfied: apricot-select in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: ray[default] in /usr/local/lib/python3.7/dist-packages (1.13.0)\n",
            "Requirement already satisfied: mosaicml in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (4.64.0)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.3.7)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (0.51.2)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.7.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (0.34.0)\n",
            "Requirement already satisfied: torch-optimizer<0.2,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (0.1.0)\n",
            "Requirement already satisfied: yahp<0.2,>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (0.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.26.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (2.28.1)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (0.13.0+cu113)\n",
            "Requirement already satisfied: torch<2,>=1.9 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (1.12.0+cu113)\n",
            "Requirement already satisfied: pyyaml<7,>=6.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (6.0)\n",
            "Requirement already satisfied: coolname<2,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (1.1.0)\n",
            "Requirement already satisfied: torchmetrics<0.8,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (0.7.3)\n",
            "Requirement already satisfied: py-cpuinfo>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (8.0.0)\n",
            "Requirement already satisfied: psutil<6,>=5.8.0 in /usr/local/lib/python3.7/dist-packages (from mosaicml) (5.9.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (2022.6.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.26.0->mosaicml) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.9->mosaicml) (4.1.1)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch-optimizer<0.2,>=0.1.0->mosaicml) (0.1.1)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics<0.8,>=0.7.0->mosaicml) (0.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics<0.8,>=0.7.0->mosaicml) (21.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.10.0->mosaicml) (7.1.2)\n",
            "Requirement already satisfied: docstring-parser<=0.15,>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from yahp<0.2,>=0.1.1->mosaicml) (0.14.1)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.10 in /usr/local/lib/python3.7/dist-packages (from yahp<0.2,>=0.1.1->mosaicml) (0.17.21)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from ruamel.yaml>=0.17.10->yahp<0.2,>=0.1.1->mosaicml) (0.2.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics<0.8,>=0.7.0->mosaicml) (3.0.9)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.0.4)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[default]) (21.4.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]) (4.3.3)\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (from ray[default]) (20.15.1)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.17.3)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.3.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (7.1.2)\n",
            "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.43.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.7.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.2.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.8.1)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.5.4)\n",
            "Requirement already satisfied: prometheus-client<0.14.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.13.1)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.7.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.10.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]) (5.2.1)\n",
            "Requirement already satisfied: gpustat>=1.0.0b1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.0.0rc1)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.3.12)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (1.7.2)\n",
            "Requirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]) (11.495.46)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]) (1.15.0)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]) (1.19.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]) (0.2.5)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (0.18.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (4.12.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (5.8.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray[default]) (3.8.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]) (1.31.6)\n",
            "Requirement already satisfied: opencensus-context>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]) (0.1.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.56.4)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.35.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (2022.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.4.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.8.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.3.5)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (2.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[default]) (2.8.2)\n",
            "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[default]) (2.5.2)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray[default]) (0.3.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Composer Options"
      ],
      "metadata": {
        "id": "FPfolzDeZ7e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "You can select any options from the all options list.\n",
        "\n",
        "Put the options you want in the options list and throughout the notebook, see \n",
        "how the composer functions you selected are applied.\n",
        "\n",
        "Some options will decrease overall training time, a few options will decrease\n",
        "per epoch training time, and a few options may not improve or harm training time\n",
        "depending on your model and dataset.\n",
        "\"\"\"\n",
        "\n",
        "all_options = [\"augmix\", \"blurpool\", \"channels_last\", \"colout\", \"cutout\", \"ema\",\n",
        "               \"factorize\", \"layer_freeze\", \"mixup\", \"rand_aug\", \"squeeze_excite\"]\n",
        "               \n",
        "options = [\"factorize\"]"
      ],
      "metadata": {
        "id": "Uv9hg-pW3b9s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "D2MKGhPKZ_AU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet18\n",
        "from cords.utils.data.datasets.SL import gen_dataset\n",
        "from torch.utils.data import Subset\n",
        "from cords.utils.config_utils import load_config_data\n",
        "import os.path as osp\n",
        "from cords.utils.data.data_utils import WeightedSubset\n",
        "from composer import functional as cf\n",
        "from composer.algorithms.augmix import AugmentAndMixTransform\n",
        "from composer.algorithms.colout import ColOutTransform\n",
        "from composer.algorithms.randaugment import RandAugmentTransform\n",
        "from ray import tune\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "IFtimJsDYBSm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "cifar10 dataset\n",
        "\n",
        "uses composer augmentations if selected"
      ],
      "metadata": {
        "id": "LE2r6j5waApX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#trainset, validset, testset, num_cls = gen_dataset('data/', 'cifar10', None, isnumpy=False)\n",
        "def get_data():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    train_transforms = [\n",
        "                        transforms.RandomCrop(32, padding=4),\n",
        "                        transforms.RandomHorizontalFlip(),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                       ]\n",
        "    if \"augmix\" in options:\n",
        "        train_transforms.append(AugmentAndMixTransform(severity=3,\n",
        "                                                       width=3,\n",
        "                                                       depth=-1,\n",
        "                                                       alpha=1.0,\n",
        "                                                       augmentation_set=\"all\"))\n",
        "    if \"colout\" in options:\n",
        "        train_transforms.append(ColOutTransform(p_row=0.15, p_col=0.15))\n",
        "    if \"rand_aug\" in options:\n",
        "        train_transforms.append(RandAugmentTransform(severity=4,\n",
        "                                                     depth=2,\n",
        "                                                     augmentation_set=\"all\"))\n",
        "\n",
        "    cifar_transform = transforms.Compose(train_transforms)\n",
        "\n",
        "    cifar_tst_transform = transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "                        ])\n",
        "\n",
        "    num_cls = 10\n",
        "\n",
        "    fullset = torchvision.datasets.CIFAR10(root='data/', train=True, download=True, transform=cifar_transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root='data/', train=False, download=True, transform=cifar_tst_transform)\n",
        "\n",
        "    validation_set_fraction = 0.1\n",
        "    num_fulltrn = len(fullset)\n",
        "    num_val = int(num_fulltrn * validation_set_fraction)\n",
        "    num_trn = num_fulltrn - num_val\n",
        "    trainset, valset = random_split(fullset, [num_trn, num_val])\n",
        "\n",
        "    return trainset, valset, testset, num_cls\n",
        "\n",
        "trainset, validset, testset, num_cls = get_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCOZOz0CYDmA",
        "outputId": "d041c282-a031-45d8-90c1-425c689c85bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trn_batch_size = 20\n",
        "val_batch_size = 20\n",
        "tst_batch_size = 1000\n",
        "\n",
        "# Creating the Data Loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=trn_batch_size,\n",
        "                                          shuffle=False, pin_memory=True)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(validset, batch_size=val_batch_size,\n",
        "                                        shuffle=False, pin_memory=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=tst_batch_size,\n",
        "                                          shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "JJji-yh0YIEY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "ResNet18 from cords utils\n",
        "\n",
        "If selected, composer functions may modify the model"
      ],
      "metadata": {
        "id": "5dQ9gvrWakPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cords.utils.models import ResNet18\n",
        "numclasses = 10\n",
        "device = 'cuda' #Device Argument\n",
        "model = ResNet18(10)\n",
        "\n",
        "if \"blurpool\" in options:\n",
        "    model = cf.apply_blurpool(model)\n",
        "if \"channels_last\" in options:\n",
        "    cf.apply_channels_last(model)\n",
        "if \"ema\" in options:\n",
        "    ema_model = copy.deepcopy(model)\n",
        "    ema_model.to(device)\n",
        "if \"factorize\" in options:\n",
        "    cf.apply_factorization(model)\n",
        "if \"squeeze_excite\" in options:\n",
        "    model = cf.apply_squeeze_excite(model)\n",
        "\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "6Qj5KIyEYJ8M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function\n",
        "cross entropy loss"
      ],
      "metadata": {
        "id": "gwlIO12Ia5w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_nored = nn.CrossEntropyLoss(reduction='none')"
      ],
      "metadata": {
        "id": "8Tvpow1wYLWZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Functions"
      ],
      "metadata": {
        "id": "pqp_iH0XbBJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ckpt(state, ckpt_path):\n",
        "    torch.save(state, ckpt_path)\n",
        "\n",
        "\n",
        "def load_ckpt(ckpt_path, model, optimizer):\n",
        "    checkpoint = torch.load(ckpt_path)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    loss = checkpoint['loss']\n",
        "    metrics = checkpoint['metrics']\n",
        "    return start_epoch, model, optimizer, loss, metrics"
      ],
      "metadata": {
        "id": "uJhZ8d3vYNBh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_cumulative_timing(mod_timing):\n",
        "    tmp = 0\n",
        "    mod_cum_timing = np.zeros(len(mod_timing))\n",
        "    for i in range(len(mod_timing)):\n",
        "        tmp += mod_timing[i]\n",
        "        mod_cum_timing[i] = tmp\n",
        "    return mod_cum_timing / 3600"
      ],
      "metadata": {
        "id": "0hx_sinTYOdX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizers and Schedulers\n",
        "stochastic gradient descent optimizer\n",
        "\n",
        "cosine scheduler"
      ],
      "metadata": {
        "id": "PvGlAd3sbJxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=1e-2,\n",
        "                                  momentum=0.9,\n",
        "                                  weight_decay=5e-4,\n",
        "                                  nesterov=False)\n",
        "\n",
        "#T_max is the maximum number of scheduler steps. Here we are using the number of epochs as the maximum number of scheduler steps.\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                       T_max=50)"
      ],
      "metadata": {
        "id": "kLHSf3WEYP3_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logger Object"
      ],
      "metadata": {
        "id": "_H7MTQSMbZ40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __get_logger(results_dir):\n",
        "  os.makedirs(results_dir, exist_ok=True)\n",
        "  # setup logger\n",
        "  plain_formatter = logging.Formatter(\"[%(asctime)s] %(name)s %(levelname)s: %(message)s\",\n",
        "                                      datefmt=\"%m/%d %H:%M:%S\")\n",
        "  logger = logging.getLogger(__name__)\n",
        "  logger.setLevel(logging.INFO)\n",
        "  s_handler = logging.StreamHandler(stream=sys.stdout)\n",
        "  s_handler.setFormatter(plain_formatter)\n",
        "  s_handler.setLevel(logging.INFO)\n",
        "  logger.addHandler(s_handler)\n",
        "  f_handler = logging.FileHandler(os.path.join(results_dir, \"results.log\"))\n",
        "  f_handler.setFormatter(plain_formatter)\n",
        "  f_handler.setLevel(logging.DEBUG)\n",
        "  logger.addHandler(f_handler)\n",
        "  logger.propagate = False\n",
        "  return logger"
      ],
      "metadata": {
        "id": "wAopp5oFYRJJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import os.path as osp\n",
        "import sys\n",
        "\n",
        "#Results logging directory\n",
        "results_dir = osp.abspath(osp.expanduser('results'))\n",
        "logger = __get_logger(results_dir)"
      ],
      "metadata": {
        "id": "6AQkQW5XYSqA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger.info(\"hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAh0aXRKYWzi",
        "outputId": "488d36e1-2001-43e0-c85e-8219f02375dc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07/23 14:23:26] __main__ INFO: hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiating GLISTER Subset Selection Dataloaders"
      ],
      "metadata": {
        "id": "cYE6pilVbfLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cords.utils.data.dataloader.SL.adaptive import GLISTERDataLoader, OLRandomDataLoader, \\\n",
        "    CRAIGDataLoader, GradMatchDataLoader, RandomDataLoader\n",
        "from dotmap import DotMap\n",
        "\n",
        "selection_strategy = 'GLISTER'\n",
        "dss_args = dict(model=model,\n",
        "                loss=criterion_nored,\n",
        "                eta=0.01,\n",
        "                num_classes=10,\n",
        "                num_epochs=50,\n",
        "                device='cuda',\n",
        "                fraction=0.1,\n",
        "                select_every=10,\n",
        "                kappa=0,\n",
        "                linear_layer=False,\n",
        "                selection_type='SL',\n",
        "                greedy='Stochastic')\n",
        "dss_args = DotMap(dss_args)\n",
        "\n",
        "dataloader = GLISTERDataLoader(trainloader, valloader, dss_args, logger, \n",
        "                                  batch_size=20, \n",
        "                                  shuffle=True,\n",
        "                                  pin_memory=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P72TwdhcYYL8",
        "outputId": "d4107452-c5d8-4751-b74b-0721aa7ca7a3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\u001b[0m\n",
            "  warnings.warn(problem)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Arguments for Training, Evaluation and Checkpointing"
      ],
      "metadata": {
        "id": "wKQlVeWCblp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Arguments\n",
        "num_epochs = 50\n",
        "\n",
        "#Arguments for results logging\n",
        "print_every = 1\n",
        "print_args = [\"val_loss\", \"val_acc\", \"tst_loss\", \"tst_acc\", \"time\"]\n",
        "\n",
        "#Argumets for checkpointing\n",
        "save_every = 20\n",
        "is_save = True\n",
        "\n",
        "#Evaluation Metrics\n",
        "trn_losses = list()\n",
        "val_losses = list()\n",
        "tst_losses = list()\n",
        "subtrn_losses = list()\n",
        "timing = list()\n",
        "trn_acc = list()\n",
        "val_acc = list()  \n",
        "tst_acc = list()  \n",
        "subtrn_acc = list()"
      ],
      "metadata": {
        "id": "hN182L3MYa8a"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Training Loop with Evaluation\n",
        "\n",
        "trains with glister dataloader from cords\n",
        "\n",
        "if selected, composer functions may modify the training loop"
      ],
      "metadata": {
        "id": "ejubgP0rbs-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "################################################# Training Loop #################################################\n",
        "\"\"\"\n",
        "for epoch in range(num_epochs):\n",
        "    subtrn_loss = 0\n",
        "    subtrn_correct = 0\n",
        "    subtrn_total = 0\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    for _, (inputs, targets, weights) in enumerate(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "        weights = weights.to(device)  \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if \"mixup\" in options:\n",
        "            inputs, y_perm, mixing = cf.mixup_batch(inputs, targets, alpha=0.2)\n",
        "        if \"cutout\" in options:\n",
        "             inputs = cf.cutout_batch(inputs, num_holes=1, length=0.5)\n",
        "             \n",
        "        outputs = model(inputs)\n",
        "        losses = criterion_nored(outputs, targets)\n",
        "        loss = torch.dot(losses, weights/(weights.sum()))\n",
        "        loss.backward()\n",
        "        subtrn_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        _, predicted = outputs.max(1)\n",
        "        subtrn_total += targets.size(0)\n",
        "        subtrn_correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if \"ema\" in options:\n",
        "            cf.compute_ema(model, ema_model, smoothing=0.99)\n",
        "        if \"layer_freeze\" in options:\n",
        "            freeze_depth, feeze_level = cf.freeze_layers(\n",
        "                                        model=model,\n",
        "                                        optimizers=optimizer,\n",
        "                                        current_duration=epoch/num_epochs,\n",
        "                                        freeze_start=0.0,\n",
        "                                        freeze_level=1.0\n",
        "                                    )\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    scheduler.step()\n",
        "    timing.append(epoch_time)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    ################################################# Evaluation Loop #################################################\n",
        "    \"\"\"\n",
        "\n",
        "    if (epoch + 1) % print_every == 0:\n",
        "        trn_loss = 0\n",
        "        trn_correct = 0\n",
        "        trn_total = 0\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        tst_correct = 0\n",
        "        tst_total = 0\n",
        "        tst_loss = 0\n",
        "        model.eval()\n",
        "\n",
        "        if (\"trn_loss\" in print_args) or (\"trn_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(trainloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    trn_loss += loss.item()\n",
        "                    if \"trn_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        trn_total += targets.size(0)\n",
        "                        trn_correct += predicted.eq(targets).sum().item()\n",
        "                trn_losses.append(trn_loss)\n",
        "\n",
        "            if \"trn_acc\" in print_args:\n",
        "                trn_acc.append(trn_correct / trn_total)\n",
        "\n",
        "        if (\"val_loss\" in print_args) or (\"val_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(valloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    val_loss += loss.item()\n",
        "                    if \"val_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        val_total += targets.size(0)\n",
        "                        val_correct += predicted.eq(targets).sum().item()\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "            if \"val_acc\" in print_args:\n",
        "                val_acc.append(val_correct / val_total)\n",
        "\n",
        "        if (\"tst_loss\" in print_args) or (\"tst_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(testloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    tst_loss += loss.item()\n",
        "                    if \"tst_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        tst_total += targets.size(0)\n",
        "                        tst_correct += predicted.eq(targets).sum().item()\n",
        "                tst_losses.append(tst_loss)\n",
        "\n",
        "            if \"tst_acc\" in print_args:\n",
        "                tst_acc.append(tst_correct / tst_total)\n",
        "\n",
        "        if \"subtrn_acc\" in print_args:\n",
        "            subtrn_acc.append(subtrn_correct / subtrn_total)\n",
        "\n",
        "        if \"subtrn_losses\" in print_args:\n",
        "            subtrn_losses.append(subtrn_loss)\n",
        "\n",
        "        print_str = \"Epoch: \" + str(epoch + 1)\n",
        "\n",
        "        \"\"\"\n",
        "        ################################################# Results Printing #################################################\n",
        "        \"\"\"\n",
        "\n",
        "        for arg in print_args:\n",
        "\n",
        "            if arg == \"val_loss\":\n",
        "                print_str += \" , \" + \"Validation Loss: \" + str(val_losses[-1])\n",
        "\n",
        "            if arg == \"val_acc\":\n",
        "                print_str += \" , \" + \"Validation Accuracy: \" + str(val_acc[-1])\n",
        "\n",
        "            if arg == \"tst_loss\":\n",
        "                print_str += \" , \" + \"Test Loss: \" + str(tst_losses[-1])\n",
        "\n",
        "            if arg == \"tst_acc\":\n",
        "                print_str += \" , \" + \"Test Accuracy: \" + str(tst_acc[-1])\n",
        "\n",
        "            if arg == \"trn_loss\":\n",
        "                print_str += \" , \" + \"Training Loss: \" + str(trn_losses[-1])\n",
        "\n",
        "            if arg == \"trn_acc\":\n",
        "                print_str += \" , \" + \"Training Accuracy: \" + str(trn_acc[-1])\n",
        "\n",
        "            if arg == \"subtrn_loss\":\n",
        "                print_str += \" , \" + \"Subset Loss: \" + str(subtrn_losses[-1])\n",
        "\n",
        "            if arg == \"subtrn_acc\":\n",
        "                print_str += \" , \" + \"Subset Accuracy: \" + str(subtrn_acc[-1])\n",
        "\n",
        "            if arg == \"time\":\n",
        "                print_str += \" , \" + \"Timing: \" + str(timing[-1])\n",
        "\n",
        "        logger.info(print_str)\n",
        "\n",
        "    \"\"\"\n",
        "    ################################################# Checkpoint Saving #################################################\n",
        "    \"\"\"\n",
        "\n",
        "    if ((epoch + 1) % save_every == 0) and is_save:\n",
        "\n",
        "        metric_dict = {}\n",
        "\n",
        "        for arg in print_args:\n",
        "            if arg == \"val_loss\":\n",
        "                metric_dict['val_loss'] = val_losses\n",
        "            if arg == \"val_acc\":\n",
        "                metric_dict['val_acc'] = val_acc\n",
        "            if arg == \"tst_loss\":\n",
        "                metric_dict['tst_loss'] = tst_losses\n",
        "            if arg == \"tst_acc\":\n",
        "                metric_dict['tst_acc'] = tst_acc\n",
        "            if arg == \"trn_loss\":\n",
        "                metric_dict['trn_loss'] = trn_losses\n",
        "            if arg == \"trn_acc\":\n",
        "                metric_dict['trn_acc'] = trn_acc\n",
        "            if arg == \"subtrn_loss\":\n",
        "                metric_dict['subtrn_loss'] = subtrn_losses\n",
        "            if arg == \"subtrn_acc\":\n",
        "                metric_dict['subtrn_acc'] = subtrn_acc\n",
        "            if arg == \"time\":\n",
        "                metric_dict['time'] = timing\n",
        "\n",
        "        ckpt_state = {\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'loss': criterion_nored,\n",
        "            'metrics': metric_dict\n",
        "        }\n",
        "\n",
        "        # save checkpoint\n",
        "        save_ckpt(ckpt_state, 'model.pt')\n",
        "        logger.info(\"Model checkpoint saved at epoch: {0:d}\".format(epoch + 1))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "################################################# Results Summary #################################################\n",
        "\"\"\"\n",
        "\n",
        "logger.info(\"{0:s} Selection Run---------------------------------\".format(selection_strategy))\n",
        "logger.info(\"Final SubsetTrn: {0:f}\".format(subtrn_loss))\n",
        "if \"val_loss\" in print_args:\n",
        "    if \"val_acc\" in print_args:\n",
        "        logger.info(\"Validation Loss: %.2f , Validation Accuracy: %.2f\", val_loss, val_acc[-1])\n",
        "    else:\n",
        "        logger.info(\"Validation Loss: %.2f\", val_loss)\n",
        "\n",
        "if \"tst_loss\" in print_args:\n",
        "    if \"tst_acc\" in print_args:\n",
        "        logger.info(\"Test Loss: %.2f, Test Accuracy: %.2f\", tst_loss, tst_acc[-1])\n",
        "    else:\n",
        "        logger.info(\"Test Data Loss: %f\", tst_loss)\n",
        "logger.info('---------------------------------------------------------------------')\n",
        "logger.info(selection_strategy)\n",
        "logger.info('---------------------------------------------------------------------')\n",
        "\n",
        "\"\"\"\n",
        "################################################# Final Results Logging #################################################\n",
        "\"\"\"\n",
        "\n",
        "if \"val_acc\" in print_args:\n",
        "    val_str = \"Validation Accuracy, \"\n",
        "    for val in val_acc:\n",
        "        val_str = val_str + \" , \" + str(val)\n",
        "    logger.info(val_str)\n",
        "\n",
        "if \"tst_acc\" in print_args:\n",
        "    tst_str = \"Test Accuracy, \"\n",
        "    for tst in tst_acc:\n",
        "        tst_str = tst_str + \" , \" + str(tst)\n",
        "    logger.info(tst_str)\n",
        "\n",
        "if \"time\" in print_args:\n",
        "    time_str = \"Time, \"\n",
        "    for t in timing:\n",
        "        time_str = time_str + \" , \" + str(t)\n",
        "    logger.info(timing)\n",
        "\n",
        "timing_array = np.array(timing)\n",
        "cum_timing = list(generate_cumulative_timing(timing_array))\n",
        "logger.info(\"Total time taken by %s = %.4f \", selection_strategy, cum_timing[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243ksusPYc59",
        "outputId": "d80bd671-850d-4877-d7a1-ff15f06ae98f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07/23 14:23:44] __main__ INFO: Epoch: 1 , Validation Loss: 498.2633208036423 , Validation Accuracy: 0.278 , Test Loss: 20.185530066490173 , Test Accuracy: 0.2819 , Timing: 6.811566114425659\n",
            "[07/23 14:23:55] __main__ INFO: Epoch: 2 , Validation Loss: 461.0968098640442 , Validation Accuracy: 0.3424 , Test Loss: 18.46556532382965 , Test Accuracy: 0.3578 , Timing: 5.375697612762451\n",
            "[07/23 14:24:07] __main__ INFO: Epoch: 3 , Validation Loss: 452.9083672761917 , Validation Accuracy: 0.3652 , Test Loss: 17.056840896606445 , Test Accuracy: 0.3903 , Timing: 5.404491424560547\n",
            "[07/23 14:24:19] __main__ INFO: Epoch: 4 , Validation Loss: 397.45928394794464 , Validation Accuracy: 0.4244 , Test Loss: 15.78402554988861 , Test Accuracy: 0.4226 , Timing: 5.387536525726318\n",
            "[07/23 14:24:31] __main__ INFO: Epoch: 5 , Validation Loss: 400.7180052995682 , Validation Accuracy: 0.4204 , Test Loss: 15.58304738998413 , Test Accuracy: 0.4468 , Timing: 5.753140211105347\n",
            "[07/23 14:24:42] __main__ INFO: Epoch: 6 , Validation Loss: 335.48674976825714 , Validation Accuracy: 0.5214 , Test Loss: 13.135119915008545 , Test Accuracy: 0.5352 , Timing: 5.354791879653931\n",
            "[07/23 14:24:54] __main__ INFO: Epoch: 7 , Validation Loss: 334.7169310450554 , Validation Accuracy: 0.508 , Test Loss: 13.523437976837158 , Test Accuracy: 0.5054 , Timing: 5.3747498989105225\n",
            "[07/23 14:25:05] __main__ INFO: Epoch: 8 , Validation Loss: 318.8116393685341 , Validation Accuracy: 0.5402 , Test Loss: 12.80486249923706 , Test Accuracy: 0.5381 , Timing: 5.370343446731567\n",
            "[07/23 14:25:17] __main__ INFO: Epoch: 9 , Validation Loss: 302.7513979077339 , Validation Accuracy: 0.5664 , Test Loss: 12.039523005485535 , Test Accuracy: 0.5719 , Timing: 5.3512585163116455\n",
            "[07/23 14:25:28] __main__ INFO: Epoch: 10 , Validation Loss: 310.32241773605347 , Validation Accuracy: 0.5612 , Test Loss: 12.312506794929504 , Test Accuracy: 0.5685 , Timing: 5.319052457809448\n",
            "[07/23 14:26:05] __main__ INFO: Epoch: 11, GLISTER dataloader subset selection finished, takes 36.1603. \n",
            "[07/23 14:26:16] __main__ INFO: Epoch: 11 , Validation Loss: 337.5032262802124 , Validation Accuracy: 0.4876 , Test Loss: 13.421566367149353 , Test Accuracy: 0.4839 , Timing: 41.481770515441895\n",
            "[07/23 14:26:28] __main__ INFO: Epoch: 12 , Validation Loss: 338.9058327078819 , Validation Accuracy: 0.4916 , Test Loss: 13.392160654067993 , Test Accuracy: 0.5015 , Timing: 5.3244006633758545\n",
            "[07/23 14:26:39] __main__ INFO: Epoch: 13 , Validation Loss: 338.58857893943787 , Validation Accuracy: 0.4784 , Test Loss: 13.950825572013855 , Test Accuracy: 0.4683 , Timing: 5.279896020889282\n",
            "[07/23 14:26:50] __main__ INFO: Epoch: 14 , Validation Loss: 309.62779688835144 , Validation Accuracy: 0.5476 , Test Loss: 12.373721241950989 , Test Accuracy: 0.5474 , Timing: 5.311993360519409\n",
            "[07/23 14:27:02] __main__ INFO: Epoch: 15 , Validation Loss: 352.265422642231 , Validation Accuracy: 0.4788 , Test Loss: 14.699706196784973 , Test Accuracy: 0.4806 , Timing: 5.2995851039886475\n",
            "[07/23 14:27:13] __main__ INFO: Epoch: 16 , Validation Loss: 278.7552314400673 , Validation Accuracy: 0.5774 , Test Loss: 10.908251523971558 , Test Accuracy: 0.588 , Timing: 5.287085771560669\n",
            "[07/23 14:27:25] __main__ INFO: Epoch: 17 , Validation Loss: 318.83833718299866 , Validation Accuracy: 0.5184 , Test Loss: 12.857579588890076 , Test Accuracy: 0.5248 , Timing: 5.26929235458374\n",
            "[07/23 14:27:36] __main__ INFO: Epoch: 18 , Validation Loss: 277.2555751800537 , Validation Accuracy: 0.5888 , Test Loss: 11.18047845363617 , Test Accuracy: 0.5921 , Timing: 5.315550327301025\n",
            "[07/23 14:27:48] __main__ INFO: Epoch: 19 , Validation Loss: 295.3898272514343 , Validation Accuracy: 0.5684 , Test Loss: 11.739343523979187 , Test Accuracy: 0.5879 , Timing: 5.3827736377716064\n",
            "[07/23 14:27:59] __main__ INFO: Epoch: 20 , Validation Loss: 308.5578546524048 , Validation Accuracy: 0.5616 , Test Loss: 12.231342315673828 , Test Accuracy: 0.5742 , Timing: 5.282711505889893\n",
            "[07/23 14:27:59] __main__ INFO: Model checkpoint saved at epoch: 20\n",
            "[07/23 14:28:35] __main__ INFO: Epoch: 21, GLISTER dataloader subset selection finished, takes 35.3297. \n",
            "[07/23 14:28:46] __main__ INFO: Epoch: 21 , Validation Loss: 261.01962661743164 , Validation Accuracy: 0.6142 , Test Loss: 10.053236722946167 , Test Accuracy: 0.6294 , Timing: 40.63294076919556\n",
            "[07/23 14:28:57] __main__ INFO: Epoch: 22 , Validation Loss: 244.16661909222603 , Validation Accuracy: 0.6402 , Test Loss: 9.844490945339203 , Test Accuracy: 0.6502 , Timing: 5.252007961273193\n",
            "[07/23 14:29:09] __main__ INFO: Epoch: 23 , Validation Loss: 244.3506456911564 , Validation Accuracy: 0.6392 , Test Loss: 9.80099505186081 , Test Accuracy: 0.6508 , Timing: 5.350571393966675\n",
            "[07/23 14:29:21] __main__ INFO: Epoch: 24 , Validation Loss: 216.9346319437027 , Validation Accuracy: 0.694 , Test Loss: 8.716741621494293 , Test Accuracy: 0.6929 , Timing: 5.626493453979492\n",
            "[07/23 14:29:32] __main__ INFO: Epoch: 25 , Validation Loss: 239.36347314715385 , Validation Accuracy: 0.6496 , Test Loss: 9.577015936374664 , Test Accuracy: 0.6549 , Timing: 5.297064542770386\n",
            "[07/23 14:29:43] __main__ INFO: Epoch: 26 , Validation Loss: 230.3490842282772 , Validation Accuracy: 0.663 , Test Loss: 9.079667568206787 , Test Accuracy: 0.6689 , Timing: 5.297215223312378\n",
            "[07/23 14:29:55] __main__ INFO: Epoch: 27 , Validation Loss: 222.29995664954185 , Validation Accuracy: 0.671 , Test Loss: 9.119889914989471 , Test Accuracy: 0.6768 , Timing: 5.300693511962891\n",
            "[07/23 14:30:06] __main__ INFO: Epoch: 28 , Validation Loss: 204.88226214051247 , Validation Accuracy: 0.712 , Test Loss: 8.442404866218567 , Test Accuracy: 0.7069 , Timing: 5.29736852645874\n",
            "[07/23 14:30:18] __main__ INFO: Epoch: 29 , Validation Loss: 212.4729649722576 , Validation Accuracy: 0.702 , Test Loss: 8.633968234062195 , Test Accuracy: 0.7158 , Timing: 5.298617601394653\n",
            "[07/23 14:30:29] __main__ INFO: Epoch: 30 , Validation Loss: 216.0394785106182 , Validation Accuracy: 0.6912 , Test Loss: 8.547975540161133 , Test Accuracy: 0.7006 , Timing: 5.355848073959351\n",
            "[07/23 14:31:05] __main__ INFO: Epoch: 31, GLISTER dataloader subset selection finished, takes 35.8040. \n",
            "[07/23 14:31:16] __main__ INFO: Epoch: 31 , Validation Loss: 198.2765584141016 , Validation Accuracy: 0.7086 , Test Loss: 8.158113777637482 , Test Accuracy: 0.6994 , Timing: 41.11812973022461\n",
            "[07/23 14:31:28] __main__ INFO: Epoch: 32 , Validation Loss: 188.73833271861076 , Validation Accuracy: 0.7166 , Test Loss: 7.8208571672439575 , Test Accuracy: 0.7167 , Timing: 5.316067934036255\n",
            "[07/23 14:31:39] __main__ INFO: Epoch: 33 , Validation Loss: 175.99555237591267 , Validation Accuracy: 0.7482 , Test Loss: 6.742508828639984 , Test Accuracy: 0.7585 , Timing: 5.304669380187988\n",
            "[07/23 14:31:51] __main__ INFO: Epoch: 34 , Validation Loss: 187.24866664409637 , Validation Accuracy: 0.725 , Test Loss: 7.918704092502594 , Test Accuracy: 0.7196 , Timing: 5.333031892776489\n",
            "[07/23 14:32:02] __main__ INFO: Epoch: 35 , Validation Loss: 179.0641914755106 , Validation Accuracy: 0.7296 , Test Loss: 7.433313548564911 , Test Accuracy: 0.7308 , Timing: 5.33627986907959\n",
            "[07/23 14:32:14] __main__ INFO: Epoch: 36 , Validation Loss: 170.50803676247597 , Validation Accuracy: 0.741 , Test Loss: 7.106729507446289 , Test Accuracy: 0.7453 , Timing: 5.274614572525024\n",
            "[07/23 14:32:25] __main__ INFO: Epoch: 37 , Validation Loss: 187.7968069911003 , Validation Accuracy: 0.7338 , Test Loss: 8.269343256950378 , Test Accuracy: 0.7254 , Timing: 5.2985076904296875\n",
            "[07/23 14:32:37] __main__ INFO: Epoch: 38 , Validation Loss: 178.59892225265503 , Validation Accuracy: 0.7348 , Test Loss: 7.5864890813827515 , Test Accuracy: 0.7309 , Timing: 5.5639214515686035\n",
            "[07/23 14:32:48] __main__ INFO: Epoch: 39 , Validation Loss: 174.0464423596859 , Validation Accuracy: 0.753 , Test Loss: 7.258369028568268 , Test Accuracy: 0.7504 , Timing: 5.333712577819824\n",
            "[07/23 14:33:00] __main__ INFO: Epoch: 40 , Validation Loss: 163.9205178618431 , Validation Accuracy: 0.759 , Test Loss: 7.068746387958527 , Test Accuracy: 0.7511 , Timing: 5.308858633041382\n",
            "[07/23 14:33:00] __main__ INFO: Model checkpoint saved at epoch: 40\n",
            "[07/23 14:33:35] __main__ INFO: Epoch: 41, GLISTER dataloader subset selection finished, takes 35.4489. \n",
            "[07/23 14:33:47] __main__ INFO: Epoch: 41 , Validation Loss: 149.8845167607069 , Validation Accuracy: 0.793 , Test Loss: 5.717836797237396 , Test Accuracy: 0.8017 , Timing: 40.740562438964844\n",
            "[07/23 14:33:58] __main__ INFO: Epoch: 42 , Validation Loss: 147.1086776703596 , Validation Accuracy: 0.7912 , Test Loss: 5.707558989524841 , Test Accuracy: 0.7972 , Timing: 5.315216064453125\n",
            "[07/23 14:34:10] __main__ INFO: Epoch: 43 , Validation Loss: 144.85461193323135 , Validation Accuracy: 0.7898 , Test Loss: 5.587714374065399 , Test Accuracy: 0.7993 , Timing: 5.445248365402222\n",
            "[07/23 14:34:21] __main__ INFO: Epoch: 44 , Validation Loss: 136.95853692293167 , Validation Accuracy: 0.8032 , Test Loss: 5.398977190256119 , Test Accuracy: 0.8098 , Timing: 5.341541290283203\n",
            "[07/23 14:34:33] __main__ INFO: Epoch: 45 , Validation Loss: 138.20563992857933 , Validation Accuracy: 0.8008 , Test Loss: 5.46336168050766 , Test Accuracy: 0.8078 , Timing: 5.342809438705444\n",
            "[07/23 14:34:44] __main__ INFO: Epoch: 46 , Validation Loss: 138.43075674772263 , Validation Accuracy: 0.8014 , Test Loss: 5.453302383422852 , Test Accuracy: 0.8078 , Timing: 5.30113959312439\n",
            "[07/23 14:34:56] __main__ INFO: Epoch: 47 , Validation Loss: 136.1581844985485 , Validation Accuracy: 0.8028 , Test Loss: 5.43110328912735 , Test Accuracy: 0.8102 , Timing: 5.291590690612793\n",
            "[07/23 14:35:07] __main__ INFO: Epoch: 48 , Validation Loss: 137.92132499814034 , Validation Accuracy: 0.7994 , Test Loss: 5.4753159284591675 , Test Accuracy: 0.8068 , Timing: 5.301108121871948\n",
            "[07/23 14:35:19] __main__ INFO: Epoch: 49 , Validation Loss: 141.56518718600273 , Validation Accuracy: 0.7972 , Test Loss: 5.417658090591431 , Test Accuracy: 0.8105 , Timing: 5.305574417114258\n",
            "[07/23 14:35:30] __main__ INFO: Epoch: 50 , Validation Loss: 137.78493347764015 , Validation Accuracy: 0.8026 , Test Loss: 5.445744872093201 , Test Accuracy: 0.8078 , Timing: 5.30756402015686\n",
            "[07/23 14:35:30] __main__ INFO: GLISTER Selection Run---------------------------------\n",
            "[07/23 14:35:30] __main__ INFO: Final SubsetTrn: 169.211441\n",
            "[07/23 14:35:30] __main__ INFO: Validation Loss: 137.78 , Validation Accuracy: 0.80\n",
            "[07/23 14:35:30] __main__ INFO: Test Loss: 5.45, Test Accuracy: 0.81\n",
            "[07/23 14:35:30] __main__ INFO: ---------------------------------------------------------------------\n",
            "[07/23 14:35:30] __main__ INFO: GLISTER\n",
            "[07/23 14:35:30] __main__ INFO: ---------------------------------------------------------------------\n",
            "[07/23 14:35:30] __main__ INFO: Validation Accuracy,  , 0.278 , 0.3424 , 0.3652 , 0.4244 , 0.4204 , 0.5214 , 0.508 , 0.5402 , 0.5664 , 0.5612 , 0.4876 , 0.4916 , 0.4784 , 0.5476 , 0.4788 , 0.5774 , 0.5184 , 0.5888 , 0.5684 , 0.5616 , 0.6142 , 0.6402 , 0.6392 , 0.694 , 0.6496 , 0.663 , 0.671 , 0.712 , 0.702 , 0.6912 , 0.7086 , 0.7166 , 0.7482 , 0.725 , 0.7296 , 0.741 , 0.7338 , 0.7348 , 0.753 , 0.759 , 0.793 , 0.7912 , 0.7898 , 0.8032 , 0.8008 , 0.8014 , 0.8028 , 0.7994 , 0.7972 , 0.8026\n",
            "[07/23 14:35:30] __main__ INFO: Test Accuracy,  , 0.2819 , 0.3578 , 0.3903 , 0.4226 , 0.4468 , 0.5352 , 0.5054 , 0.5381 , 0.5719 , 0.5685 , 0.4839 , 0.5015 , 0.4683 , 0.5474 , 0.4806 , 0.588 , 0.5248 , 0.5921 , 0.5879 , 0.5742 , 0.6294 , 0.6502 , 0.6508 , 0.6929 , 0.6549 , 0.6689 , 0.6768 , 0.7069 , 0.7158 , 0.7006 , 0.6994 , 0.7167 , 0.7585 , 0.7196 , 0.7308 , 0.7453 , 0.7254 , 0.7309 , 0.7504 , 0.7511 , 0.8017 , 0.7972 , 0.7993 , 0.8098 , 0.8078 , 0.8078 , 0.8102 , 0.8068 , 0.8105 , 0.8078\n",
            "[07/23 14:35:30] __main__ INFO: [6.811566114425659, 5.375697612762451, 5.404491424560547, 5.387536525726318, 5.753140211105347, 5.354791879653931, 5.3747498989105225, 5.370343446731567, 5.3512585163116455, 5.319052457809448, 41.481770515441895, 5.3244006633758545, 5.279896020889282, 5.311993360519409, 5.2995851039886475, 5.287085771560669, 5.26929235458374, 5.315550327301025, 5.3827736377716064, 5.282711505889893, 40.63294076919556, 5.252007961273193, 5.350571393966675, 5.626493453979492, 5.297064542770386, 5.297215223312378, 5.300693511962891, 5.29736852645874, 5.298617601394653, 5.355848073959351, 41.11812973022461, 5.316067934036255, 5.304669380187988, 5.333031892776489, 5.33627986907959, 5.274614572525024, 5.2985076904296875, 5.5639214515686035, 5.333712577819824, 5.308858633041382, 40.740562438964844, 5.315216064453125, 5.445248365402222, 5.341541290283203, 5.342809438705444, 5.30113959312439, 5.291590690612793, 5.301108121871948, 5.305574417114258, 5.30756402015686]\n",
            "[07/23 14:35:30] __main__ INFO: Total time taken by GLISTER = 0.1143 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Average Time / Epoch: {np.mean(timing)} \\nTotal Epochs: {num_epochs}\")"
      ],
      "metadata": {
        "id": "rEw6yODiL_CJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d7793c1-d6d7-4380-c74c-aa399b8a5442"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Time / Epoch: 8.226533131599426 \n",
            "Total Epochs: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU info"
      ],
      "metadata": {
        "id": "RA0IHPHCbyDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "OiR1Rbi5CgrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cffeff4-c6e1-4709-edce-c634395a9970"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul 23 14:35:30 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0    40W / 250W |   5069MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9hnoIcO1L1iy"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}